spark-shell

val df = spark.read.format("csv").load("s3://airline-delay-dilan/input/DelayedFlights-updated.csv")

df.show()

df.write.format("parquet").partitionBy("_c1").save("s3://airline-delay-dilan/sparkSession/DelayedFlights-new");

val df2 = spark.read.format("parquet").load("s3://airline-delay-dilan/sparkSession/DelayedFlights-new")

df2.show();

df2.createOrReplaceTempView("delay_flights");



val result1 = spark.sql("SELECT _c1 AS Year, avg((_c25 /_c15)*100) avg_carrier_delay from delay_flights WHERE _c1 >= 2003 AND _c1 <= 2010 GROUP BY Year ORDER BY Year ASC");
spark.time(result1.show());

val result3 = spark.sql("SELECT _c1 AS Year, avg((_c26 /_c15)*100) avg_weather_delay from delay_flights WHERE _c1 >= 2003 AND _c1 <= 2010 GROUP BY Year ORDER BY Year ASC");
spark.time(result3.show());

val result2 = spark.sql("SELECT _c1 AS Year, avg((_c27 /_c15)*100) avg_nas_delay from delay_flights WHERE _c1 >= 2003 AND _c1 <= 2010 GROUP BY Year ORDER BY Year ASC");
spark.time(result2.show());

val result5 = spark.sql("SELECT _c1 AS Year, avg((_c28 /_c15)*100) avg_security_delay from delay_flights WHERE _c1 >= 2003 AND _c1 <= 2010 GROUP BY Year ORDER BY Year ASC");
spark.time(result5.show());

val result4 = spark.sql("SELECT _c1 AS Year, avg((_c29 /_c15)*100) avg_late_aircraft_delay from delay_flights WHERE _c1 >= 2003 AND _c1 <= 2010 GROUP BY Year ORDER BY Year ASC");
spark.time(result4.show());


